{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "wss = Webservice.list(workspace = ws, compute_type='AKS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your automl model name will be different than that referenced in this example, grab your model name and update this code appropriately\n",
    "models = Model.list(ws)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws, name=\"AutoML101a437ac19\")\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The writefile command has to be the first line in the following block. \n",
    "# In testing this example, the \"ModelDataCollector\" based predictions did not seem to work and still being investigated \n",
    "# For the moment, please use this simplified prediction interface. It is possible that the ModelDataCollector may depend on azure batch under the covers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score_dc.py\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import azureml.train.automl\n",
    "import json\n",
    "import numpy as np\n",
    "import azureml.train.automl as AutoML\n",
    "\n",
    "def init():\n",
    "    try:\n",
    "        # One-time initialization of predictive model and scaler\n",
    "        from azureml.core.model import Model\n",
    "        from sklearn.externals import joblib\n",
    "        global model\n",
    "\n",
    "        model_name = 'AutoML101a437ac19'\n",
    "        print (\"Initializing model at \" + time.strftime(\"%H:%M:%S\"))\n",
    "        model_path = Model.get_model_path(model_name = model_name)\n",
    "        model = joblib.load(model_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Exception during init: ', str(e))\n",
    "\n",
    "def run(input_json):\n",
    "    try:\n",
    "        inputs = json.loads(input_json)['text']\n",
    "        # Get the predictions...\n",
    "        prediction = model.predict(pd.DataFrame(inputs, columns = ['review']))\n",
    "        #prediction = json.dumps(prediction)\n",
    "        prediction = json.dumps({\"result\": prediction.tolist()})\n",
    "        #prediction = inputs\n",
    "    except Exception as e:\n",
    "        prediction = str(e)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional, skip this step if the above wworks, you can create a super simple reflection scoring file to make sure the AKS cluster is working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score_dc.py\n",
    "import json\n",
    "\n",
    "\n",
    "def init():\n",
    "    print(\"This is init\")\n",
    "\n",
    "\n",
    "def run(data):\n",
    "    test = json.loads(data)\n",
    "    print(f\"received data {test}\")\n",
    "    return f\"test is {test}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, the following section uses the newer \"Environment\" class/api to provision the docker environment. \n",
    "# The ContainerImage.image_configuration ahd ContainerImage.create style of image creation was tested but does\n",
    "# not work possibly because it depends on azure batch under the covers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(\"mytestenv2\")\n",
    "#myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['numpy','scikit-learn', 'packaging','py-xgboost<=0.80'])\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['numpy','scikit-learn', 'py-xgboost<=0.80'],\n",
    "                                                           pip_packages=['azureml-defaults', 'azureml-train-automl', 'azureml-monitoring','azureml-telemetry'])\n",
    "\n",
    "# Enable Docker\n",
    "docker_config = DockerConfiguration(use_docker=True)\n",
    "myenv.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig \n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration(collect_model_data=True,\n",
    "                                                enable_app_insights=True)\n",
    "aks_service_name ='sentiment-api-with-data-coll'\n",
    "aks_target = AksCompute(ws,\"k8-inf-comp\")\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score_dc.py', environment=myenv)\n",
    "#aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                      name=aks_service_name,\n",
    "                      models=[model],\n",
    "                      inference_config=inference_config,\n",
    "                      deployment_config=aks_config,\n",
    "                      deployment_target=aks_target,\n",
    "                      overwrite=True)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "key1, Key2 = service.get_keys()\n",
    "\n",
    "headers = {'Content-Type':'application/json',\n",
    "           'Authorization': 'Bearer ' + key1}\n",
    "\n",
    "data = {\"text\": ['the food was horrible',\n",
    "                 'wow, this movie was truely great, I totally enjoyed it!',\n",
    "                 'why the heck was my package not delivered on time?', \n",
    "                 'This movie sucks!!']}\n",
    "print(key1)\n",
    "print(service.scoring_uri)\n",
    "print(service)\n",
    "\n",
    "resp = requests.post(service.scoring_uri, json=data, headers=headers)\n",
    "print(resp)\n",
    "print(\"Prediction Results:\", resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If all goes well you will see something like \n",
    "#http://10.0.3.98:80/api/v1/service/sentiment-api-with-data-coll/score\n",
    "#AksWebservice(workspace=Workspace.create(name='ngc-test-wkspace-55', subscription_id='8c98ce0c-4c4f-4ad4-8bd9-c026f79c0889', resource_group='ngcml-dev-55'), name=sentiment-api-with-data-coll, image_id=None, compute_type=None, state=AKS, scoring_uri=Healthy, tags=http://10.0.3.98:80/api/v1/service/sentiment-api-with-data-coll/score, properties=None, created_by={'hasInferenceSchema': 'False', 'hasHttps': 'False'})\n",
    "#<Response [200]>\n",
    "#Prediction Results: {\"result\": [\"negative\", \"positive\", \"negative\", \"negative\"]}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
